{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c75e2da",
   "metadata": {},
   "source": [
    "# Digit Classifier made with Micrograd\n",
    "\n",
    "This model is a digit classifier built from scratch using a neural network inspired by [Karpathy's Micrograd](https://github.com/karpathy/micrograd). It was trained on 1000 images that were 14 x 14 in order to save time. This was done without using deep learning libraries like PyTorch or TensorFlow. The model was trained for 3 hours and achieved a 71% accuracy.\n",
    "\n",
    "## Architecture\n",
    "- Input: `196` (14 x 14)\n",
    "- Hidden layers:\n",
    "    - 64 neurons with `tanh` activation\n",
    "    - 32 neurons with `tanh` activation\n",
    "- Output layer: 10 neurons (one per digit)\n",
    "\n",
    "  ```python\n",
    "  # Here is the model declaration\n",
    "  model = MLP(196, [64, 32, 10])\n",
    "\n",
    "## How to load micrograd model\n",
    "```python\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load saved parameter values (list of floats)\n",
    "with open(\"models/micrograd_model.pkl\", \"rb\") as f:\n",
    "    saved_params = pickle.load(f)\n",
    "\n",
    "for p, val in zip(model.parameters(), saved_params):\n",
    "    p.data = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # used for defining cost function\n",
    "import numpy as np # used for accessing dataset\n",
    "from Value import Value # custom object implemented in MLP from Karpathy's Micrograd\n",
    "from MLP import * # multi layer perceptron backbone of mdodel\n",
    "from sklearn.datasets import fetch_openml # to access MNIST dataset\n",
    "import matplotlib.pyplot as plt # To visualize digits\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d079559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "X = X / 255.0 # normalize pixels\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c1417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting data\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "split = int(0.8 * len(X))\n",
    "train_idx, test_idx = indices[:split], indices[split:]\n",
    "X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bede3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie. 4 = [0,0,0,0,1,0,0,0,0,0]\n",
    "def encode_labels(y):\n",
    "    one_hot = np.zeros((len(y), 10))\n",
    "    one_hot[np.arange(len(y)), y] = 1\n",
    "    return one_hot\n",
    "y_train_encoded = encode_labels(y_train)\n",
    "y_test_encoded = encode_labels(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2e3092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model that will be used\n",
    "model = MLP(196, [64, 32, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3be27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cross entropy loss for cost function\n",
    "def softmax(logits):\n",
    "    exps = [x.exp() for x in logits]\n",
    "    sum_exps = sum(exps, Value(0))\n",
    "    probs = [e / sum_exps for e in exps]\n",
    "    return probs\n",
    "\n",
    "def cross_entropy_loss(logits, true_label):\n",
    "    probs = softmax(logits)\n",
    "    loss = Value(0)\n",
    "    for p, t in zip(probs, true_label):\n",
    "        if t == 1:\n",
    "            loss -= p.log()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate will decay by 4% each epoch\n",
    "def update_weights(model, base_lr, e, decay=0.96):\n",
    "    lr = base_lr * (decay ** e)\n",
    "    for p in model.parameters():\n",
    "         p.data += -lr * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddc285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# resizer to compress images\n",
    "def resize_dataset(X, new_size=(14,14)):\n",
    "    resized_images = []\n",
    "    for img_array in X:\n",
    "        img = Image.fromarray(img_array)\n",
    "        img_small = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        resized_images.append(np.array(img_small)) \n",
    "    return np.array(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 1.3524259108072207\n",
      "Epoch: 27, Loss: 1.340797374785405\n",
      "Epoch: 28, Loss: 1.3262896825932062\n",
      "Epoch: 29, Loss: 1.3036682211355057\n",
      "Epoch: 30, Loss: 1.2853805441742288\n",
      "Epoch: 31, Loss: 1.2613890733299704\n",
      "Epoch: 32, Loss: 1.2800803802391847\n",
      "Epoch: 33, Loss: 1.2548047463885272\n",
      "Epoch: 34, Loss: 1.2377037367228227\n",
      "Epoch: 35, Loss: 1.246479296332746\n",
      "Epoch: 36, Loss: 1.2069004677443043\n",
      "Epoch: 37, Loss: 1.180867781070629\n",
      "Epoch: 38, Loss: 1.1941594524635193\n",
      "Epoch: 39, Loss: 1.1883555695244263\n",
      "Epoch: 40, Loss: 1.1519569070785027\n"
     ]
    }
   ],
   "source": [
    "# resized to save time\n",
    "X_train = resize_dataset(X_train, (14, 14))\n",
    "X_test = resize_dataset(X_test, (14, 14))\n",
    "X_train = X_train[:1000]\n",
    "y_train_encoded = y_train_encoded[:1000]\n",
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for x, y_true in zip(X_train, y_train_encoded):\n",
    "        # forward pass\n",
    "        x_val = [Value(xi) for xi in np.ravel(x)]\n",
    "        y_pred = model(x_val)\n",
    "        loss = cross_entropy_loss(y_pred, y_true)\n",
    "\n",
    "        # zero gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        update_weights(model, base_lr=0.2, e=epoch)\n",
    "        total_loss += loss.data\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {total_loss / len((X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d317de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 71.00%\n"
     ]
    }
   ],
   "source": [
    "# achieved 71% accuracy\n",
    "correct = 0\n",
    "total = len(X_test[:1000])\n",
    "X_test_resized = resize_dataset(X_test, (14, 14))\n",
    "\n",
    "for x, y_true in zip(X_test_resized[:1000], y_test[:1000]):\n",
    "    x_vals = [Value(xi) for xi in np.ravel(x)]\n",
    "    y_pred = model(x_vals)\n",
    "    pred_label = np.argmax([p.data for p in y_pred])\n",
    "    \n",
    "    if pred_label == y_true:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1189351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "i = 13\n",
    "X_test_resized = resize_dataset(X_test, (14, 14))\n",
    "img_resized = X_test_resized[i]\n",
    "img = X_test[i]\n",
    "label = y_test[i]\n",
    "\n",
    "# Predict\n",
    "x_vals = [Value(xi) for xi in np.ravel(img_resized)]\n",
    "y_pred = model(x_vals)\n",
    "pred_label = np.argmax([p.data for p in y_pred])\n",
    "\n",
    "\n",
    "plt.imshow(img.reshape(28, 28), cmap='gray')  \n",
    "plt.title(f\"Predicted: {pred_label}, Actual: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6872e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "params = [p.data for p in model.parameters()]\n",
    "with open(\"models/micrograd_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(params, f)\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82ace8",
   "metadata": {},
   "source": [
    "## Digit Classifier made with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc578a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2e71c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load saved parameter values (list of floats)\n",
    "with open(\"models/micrograd_model.pkl\", \"rb\") as f:\n",
    "    saved_params = pickle.load(f)\n",
    "\n",
    "for p, val in zip(model.parameters(), saved_params):\n",
    "    p.data = val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975d3b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
